{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "- Find false innocents, could be through:\n",
    "    - connections with many criminal nodes?\n",
    "    - connection to a big criminal hub?\n",
    "\n",
    "# Assumptions\n",
    "- People connected to a crime as suspect or suspect/victim will be considered as being guilty of the crime they are connected to\n",
    "- \n",
    "\n",
    "## Node categorisation\n",
    "- criminal nodes: nodes that have been a suspect in a acrime at least once\n",
    "- innocent nodes: nodes that have been only victims and/or witness\n",
    "\n",
    "## Suspect role\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work plan\n",
    "Research question: is it possible to detect criminals that were not previously caught? - \"criminal\" disguised as \"innocent\"\n",
    "\n",
    "- Does a strong link prediction between a criminal and an innocent suggests that the innocent might be a criminal in disguise?\n",
    "- Compare the results from link prediction and community detection\n",
    "- If they are in the same community? Is that an even stronger indication of a possible criminal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('seaborn version', sns.__version__)\n",
    "print('pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = '..//Data//out.moreno_crime_crime'\n",
    "gender = '..//Data//ent.moreno_crime_crime.person.sex'\n",
    "name = '..//Data//ent.moreno_crime_crime.person.name'\n",
    "role = '..//Data//rel.moreno_crime_crime.person.role'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjancency list as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al = pd.read_csv(al, sep=\" \", names=['person', 'crime'], index_col=False)\n",
    "df_al['person'] = 'p' + df_al['person'].astype(str)\n",
    "df_al['crime'] = 'c' + df_al['crime'].astype(str)\n",
    "df_al.head(3)\n",
    "df_al.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = pd.read_csv(gender, sep=\" \", header=None, names=['gender'])\n",
    "df_gender['person'] = 'p' + df_gender.index.astype(str)\n",
    "df_gender.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = pd.read_csv(name, sep=\" \", header=None, names=['name'])\n",
    "df_name['person'] = 'p' + df_name.index.astype(str)\n",
    "df_name.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_role = pd.read_csv(role, sep=\",\", header=None, names=['role'])\n",
    "# df_role.head(3)\n",
    "df_role.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join adjancency list with role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al_roles = df_al.join(df_role)\n",
    "df_al_roles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al_roles[df_al_roles['person'] == 'p336']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group bys gives us the same as degree distribution\n",
    "# df_al_roles.groupby(by='person', dropna=False).count()\n",
    "# df_al_roles.groupby(by=['crime', 'role'], dropna=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following are used to create the graph\n",
    "people = df_al['person'].unique()\n",
    "crimes = df_al['crime'].unique()\n",
    "roles = df_role['role'].unique()\n",
    "\n",
    "# print stats\n",
    "print('Number of people:', len(people))\n",
    "print('Number of crimes:', len(crimes))\n",
    "print('Number of roles:', len(roles))\n",
    "print('Number of edges:', len(df_al_roles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown of roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_role.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G=nx.from_pandas_dataframe(df_al_roles, 0, 'b', ['weight', 'cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create networkx graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# # add nodes\n",
    "for i in range(len(people)):\n",
    "    G.add_node(people[i], name=df_name['name'][i], gender=df_gender['gender'][i], bipartite=0)\n",
    "\n",
    "for i in range(len(crimes)):\n",
    "    G.add_node(crimes[i], bipartite=1)\n",
    "\n",
    "# # add edges\n",
    "for i in range(len(df_al)):\n",
    "    G.add_edge(df_al_roles['person'][i], df_al_roles['crime'][i], role=df_al_roles['role'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign node status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from Dee\n",
    "# Initialize a dictionary based on people nodes to keep track of all roles per node\n",
    "p_nodes = {el:[] for el in people}\n",
    "\n",
    "# Add all the edge attributes to a dictionary of people nodes\n",
    "for key,value in nx.get_edge_attributes(G, 'role').items():\n",
    "    for part in key:\n",
    "        if part in people:\n",
    "            p_nodes[part].append(value)\n",
    "\n",
    "# print(p_nodes['p1']) # List of all roles from p1\n",
    "\n",
    "# Initialize a dictionary to keep track of who is a \"criminal\"\n",
    "status = {el:[] for el in people}\n",
    "    \n",
    "# Loop through all roles per node, and deem them criminals if ever they have been a suspect\n",
    "for key in p_nodes:\n",
    "    if 'Suspect' in p_nodes[key]:\n",
    "        status[key] = \"criminal\"\n",
    "    elif 'Victim Suspect' in p_nodes[key]:\n",
    "        status[key] = \"criminal\"\n",
    "    else:\n",
    "        status[key] = \"innocent\"\n",
    "\n",
    "print(status['p336']) # Verify that p1 is deemed \"criminal\"\n",
    "\n",
    "# Convert to pandas df\n",
    "criminals_df = pd.DataFrame(status.items(), columns=['node', 'criminal_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add node status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through rows in the data frame and add the attribute of Criminal Status\n",
    "for index, row in criminals_df.iterrows():\n",
    "    #print(row['node'])\n",
    "    G.nodes[row['node']]['criminal_status'] = row['criminal_status']\n",
    "\n",
    "print(nx.get_node_attributes(G, 'criminal_status')['p1']) # check name of person 'p1' = 'Criminal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top and bottom nodes for projection and plotting\n",
    "people_nodes = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "crime_nodes = set(G) - people_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only biggest component\n",
    "# pos = nx.spring_layout(G)\n",
    "# posB = nx.bipartite_layout(G, people_nodes)\n",
    "G_draw = nx.draw_spring(G,node_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get degree of all nodes\n",
    "Node degreee of **people** nodes if the number of crimes they were involved in.  \n",
    "Node degree of **crime** nodes is the number of people involved in the crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dict with all node degrees to add as attribute\n",
    "node_degrees = dict()\n",
    "\n",
    "# Creating dict for each node type\n",
    "people_degrees = dict()\n",
    "crimes_degrees = dict()\n",
    "\n",
    "# for loop to populate dicts above\n",
    "for node in G.nodes:\n",
    "    # print(G.edges(node, data=True))\n",
    "    node_degrees[node] = G.degree(node)\n",
    "    if node.startswith('p') == True:\n",
    "        people_degrees[node] = G.degree(node)\n",
    "    else:\n",
    "        crimes_degrees[node] = G.degree(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = pd.read_csv(gender, sep=\" \", header=None, names=['gender'])\n",
    "df_gender['person'] = 'p' + df_gender.index.astype(str)\n",
    "df_gender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add node degree as node attribute in graph G\n",
    "nx.set_node_attributes(G, node_degrees, \"node_degree\")\n",
    "\n",
    "# and check it worked\n",
    "# nx.get_node_attributes(G, 'node_degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dataframe including all node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://stackoverflow.com/a/50775962\n",
    "# make pandas dataframe from graph with node attributes\n",
    "df_G = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\n",
    "df_G\n",
    "# df_G['criminal_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection on people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_proj = bipartite.weighted_projected_graph(G, people_nodes, ratio=False)\n",
    "list(G_proj.edges(data=True))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Num. of nodes: {} \\nNum. of edges: {} \\nIs bipartite? {} \\nIs connected? {}'.format(\n",
    "        G_proj.number_of_nodes(), \n",
    "        G_proj.number_of_edges(), \n",
    "        nx.is_bipartite(G_proj),\n",
    "        nx.is_connected(G_proj)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(nx.get_edge_attributes(G_proj, 'weight').values())\n",
    "\n",
    "# plot weights\n",
    "plt.hist(weights, bins = 10, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People of interest. Pairs that are connected by 5 crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_w = list(G_proj.edges(data=True))\n",
    "\n",
    "for i in edge_w:\n",
    "    if i[2]['weight'] > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adjacency matrix\n",
    "A = nx.adjacency_matrix(G_proj, weight='weight')\n",
    "A = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[A > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot adjacency matrix\n",
    "plt.title('Adjacency Matrix')\n",
    "# plt.imshow(A, cmap='Greys', markersize = 3)\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(8,8))\n",
    "plt.spy(A, markersize = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph visualisation\n",
    "nx.draw_spring(G_proj, node_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction on projected graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from: https://www.networkatlas.eu/exercise.htm?c=20&e=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkpred_pa = list(nx.preferential_attachment(G_proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in decreasing score\n",
    "linkpred_pa.sort(key = lambda tup: tup[2], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10\n",
    "for edge_score in linkpred_pa[:10]:\n",
    "   print(edge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from: https://www.networkatlas.eu/exercise.htm?c=20&e=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the other link prediction methods implemented in networkx\n",
    "linkpred_ja = list(nx.jaccard_coefficient(G_proj))\n",
    "linkpred_aa = list(nx.adamic_adar_index(G_proj))\n",
    "linkpred_ra = list(nx.resource_allocation_index(G_proj))\n",
    "\n",
    "linkpred_ja.sort(key = lambda tup: tup[2], reverse = True)\n",
    "linkpred_aa.sort(key = lambda tup: tup[2], reverse = True)\n",
    "linkpred_ra.sort(key = lambda tup: tup[2], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top predictions\n",
    "print(\"PrefAtt\\tJaccard\\tAdamAd\\tResAll\")\n",
    "for i in range(5):\n",
    "   print(\"%s\\t%s\\t%s\\t%s\" % (linkpred_pa[i], linkpred_ja[i], linkpred_aa[i], linkpred_ra[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkpred = pd.DataFrame(linkpred_ra, columns=['node1', 'node2', 'resource_allocation_score'])\n",
    "df_linkpred['node1_status'] = df_linkpred['node1'].map(status)\n",
    "df_linkpred['node2_status'] = df_linkpred['node2'].map(status)\n",
    "# df_linkpred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkpred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_linkpred[df_linkpred['resource_allocation_score'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(df_linkpred[df_linkpred['resource_allocation_score'] > .25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G.iloc[410,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G.iloc[282,:]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82a91a22060084f3e8dbe72ba49a002eddd687e7ed0e7d249946fe1b995c1ddc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
