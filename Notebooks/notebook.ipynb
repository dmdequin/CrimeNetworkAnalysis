{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "union-dynamics",
   "metadata": {},
   "source": [
    "# Network Analysis Project\n",
    "## Crime Network Analysis\n",
    "Professor: Michele Coscia\n",
    "\n",
    "This notebook contains all of the code developed for the Network Analysis Course at ITU. We will be using...**finish**\n",
    "\n",
    "**Add Description**\n",
    "\n",
    "Group 10:  \n",
    "Carl August Wismer ([cwis@itu.dk](mailto:cwis@itu.dk))  <br>\n",
    "Crisanna Cornish ([ccor@itu.dk](mailto:ccor@itu.dk))  <br>\n",
    "Danielle Dequin ([ddeq@itu.dk](mailto:ddeq@itu.dk))  <br>\n",
    "Maria Do Carmo Madeira Santos Silva Passos de Sousa ([mdom@itu.dk](mailto:mdom@itu.dk))  <br>\n",
    "Moneeca Abru Iftikhar Latif ([abml@itu.dk](mailto:abml@itu.dk))  <br>\n",
    "Sabrina Fonseca Pereira ([sabf@itu.dk](mailto:sabf@itu.dk))  <br>\n",
    "\n",
    "Created: 27-09-2021  \n",
    "Last Modified: 23-10-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-triumph",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "The data are a network of associations among suspects, victims, and/or witnesses involved in crimes in St. Louis in the 1990s. Data are derived from police records, via snowball sampling from five initial homicides. Left nodes are people, right nodes are crime events, and edges connect people to particular crimes events they were associated with. Metadata includes names, genders, and roles (suspects, victims, and/or witnesses).\n",
    "\n",
    "This is an undirected, unweighted, bipartite network with 1380 nodes and 1476 edges.\n",
    "\n",
    "Data can be downloaded [here](http://konect.cc/networks/moreno_crime/) or [here](https://networks.skewed.de/net/crime)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-radiation",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "import powerlaw as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-brake",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../Data/out.moreno_crime_crime'\n",
    "ROLE = '../Data/rel.moreno_crime_crime.person.role'\n",
    "NAME = '../Data/ent.moreno_crime_crime.person.name'\n",
    "SEX =  '../Data/ent.moreno_crime_crime.person.sex'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-dress",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-suggestion",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fu(x, a, l):\n",
    "    \"\"\"A custom function which is a power law with its exponential truncation. From 'Atlas for the Aspiring\n",
    "    Network Scientist' Chapter 6\n",
    "    \"\"\"\n",
    "    return (x ** a) * np.exp(-l * x) \n",
    "\n",
    "def log_f(x, a, l):\n",
    "    \"\"\"The Logarithm of f, used to fit the log of the CCDF using curve_fit\"\"\"\n",
    "    return np.log10(f(x, a, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-delay",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA) as f:\n",
    "    data = f.read().splitlines()\n",
    "    \n",
    "with open(ROLE) as f:\n",
    "    role = f.read().splitlines()\n",
    "    \n",
    "with open(NAME) as f:\n",
    "    name = f.read().splitlines()\n",
    "    \n",
    "with open(SEX) as f:\n",
    "    sex = f.read().splitlines()\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    data[i] = 'p' + data[i] # adds 'p' to the People nodes to differentiate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.read_edgelist(data) # read edgelist in\n",
    "print(len(B.nodes()), len(B.edges())) # sanity check (1380, 1476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(DATA, dtype=str)\n",
    "a = np.unique(graph[:,0]) # people nodes\n",
    "b = np.unique(graph[:,1]) # crime nodes\n",
    "a = ['p' + a for a in a] # add string to differentiate\n",
    "\n",
    "print(f\"There are {len(a)} unique people and {len(b)} unique crime events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-crack",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "for j in range(len(a)):\n",
    "    G.add_node(a[j], bipartite=0, data=True, name=name[j], sex=sex[j]) #Add attributes name and sex\n",
    "\n",
    "G.add_nodes_from(b, bipartite=1, data=True)\n",
    "\n",
    "# add edges\n",
    "i = 0\n",
    "for edge in B.edges():\n",
    "    G.add_edge(edge[0], edge[1], role=role[i]) # why role is in a list?\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(\n",
    "    'Num. of nodes: {} \\nNum. of edges: {} \\nIs bipartite? {} \\nIs connected? {}'.format(\n",
    "        G.number_of_nodes(), \n",
    "        G.number_of_edges(), \n",
    "        nx.is_bipartite(G),\n",
    "        nx.is_connected(G)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-northern",
   "metadata": {},
   "source": [
    "From the [official Networkx docs](https://networkx.org/documentation/stable/reference/algorithms/bipartite.html):\n",
    "\n",
    "Many algorithms of the bipartite module of NetworkX require, as an argument, a container with all the nodes that belong to one set, in addition to the bipartite graph B. The functions in the bipartite package do not check that the node set is actually correct nor that the input graph is actually bipartite. If B is connected, you can find the two node sets using a two-coloring algorithm:\n",
    "\n",
    "```py\n",
    ">>> nx.is_connected(B)\n",
    "True\n",
    ">>> bottom_nodes, top_nodes = bipartite.sets(B)\n",
    "```\n",
    "However, if the input graph is not connected, there are more than one possible colorations. This is the reason why we require the user to pass a container with all nodes of one bipartite node set as an argument to most bipartite functions. In the face of ambiguity, we refuse the temptation to guess and raise an AmbiguousSolution Exception if the input graph for bipartite.sets is disconnected.\n",
    "\n",
    "Using the bipartite node attribute, you can easily get the two node sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0} # people\n",
    "bottom_nodes = set(G) - top_nodes # crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-suspect",
   "metadata": {},
   "source": [
    "## Adding metadata to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.get_node_attributes(G, 'name')['p1']) # check name of person 'p1' = 'AbelDennis'\n",
    "print(nx.get_node_attributes(G, 'sex')['p1']) # check sex of person 'p1' = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_edge_attributes(G, 'role')['p1', '1']\n",
    "# check role of edge between person p1 and crime 1 = 'Suspect'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-conservative",
   "metadata": {},
   "source": [
    "# Finding Largest Connected Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-gallery",
   "metadata": {},
   "source": [
    "### *LCC:* Here we find that the largest connected component contains 1263 nodes (out of 1380 total nodes). This has a large majority of the nodes in the connected component. We do futher analysis to see if we should focus on this component alone as we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components in the graph sorted in descendent order\n",
    "Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "\n",
    "# Selecting the biggest component\n",
    "G0 = G.subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of nodes for the LCC\n",
    "top_nodes_lcc = {n for n, d in G0.nodes(data=True) if d[\"bipartite\"] == 0} # people\n",
    "bottom_nodes_lcc = set(G0) - top_nodes_lcc      # crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nodes for each component and number of components\n",
    "comp_list = []\n",
    "for comp in Gcc:\n",
    "    comp_len = len(comp)\n",
    "    comp_list.append(comp_len)\n",
    "\n",
    "BC_perc = round(comp_list[0]/sum(comp_list) * 100,3)\n",
    "\n",
    "print(f'Number of nodes for each components: {comp_list} and number of components: {len(comp_list)}.')\n",
    "print(f'The number of number of nodes in the biggest component represents {BC_perc} % of all nodes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-people",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-premiere",
   "metadata": {},
   "source": [
    "## Average Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-liability",
   "metadata": {},
   "source": [
    "### *Density:* probability that a random node pair is connected or, the number of edges in a network over the total possible number of edges that can exist given the number of nodes. \n",
    "    In our case, we have a probablity of 0.003 which means that our network is quite sparse. Additionally, we see that the probability is very similar for the LCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Density: {} \\nAvarage clustering: {}'.format(\n",
    "        round(bipartite.density(G, bottom_nodes),3),\n",
    "        round(bipartite.average_clustering(G),3)\n",
    "        )\n",
    "    )\n",
    "print('\\n')\n",
    "print('Density LCC: {} \\nAverage Clustering LCC: {}'.format(\n",
    "        round(bipartite.density(G0, bottom_nodes_lcc),3), \n",
    "        round(bipartite.average_clustering(G0),3)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-mention",
   "metadata": {},
   "source": [
    "## Another way to get Average Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-gnome",
   "metadata": {},
   "source": [
    "### *Clustering coefficient:* number of common neighbors around a node connected to each other. How often does a triad (set of three connected nodes) closes down into a triangle (three nodes that are all connected to each other)? \n",
    "#### Note_1: in the formula, we multiply by 3 because a single triangle closes three triads.\n",
    "#### Note_2: local, global and average clustering coefficients are different.\n",
    "\n",
    "    In our case, almost half of the triads (0.43) in the network close to form a triangle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = bipartite.clustering(G)\n",
    "print(f'Clustering of Entire Network: {round(sum(cluster.values())/len(cluster.values()),5)}')\n",
    "\n",
    "cluster2 = bipartite.clustering(G0)\n",
    "print(f'Clustering for LCC: {round(sum(cluster2.values())/len(cluster2.values()),5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-graphic",
   "metadata": {},
   "source": [
    "### **Looking for both density and clustering coefficient values, our network follows the real world network caracterists having few connections per node, but these connections tend to be clustered in the same neighborhood. Nodes tend to close triangles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-consent",
   "metadata": {},
   "source": [
    "## Global Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entire graph\n",
    "global_clustering = bipartite.robins_alexander_clustering(G)\n",
    "print(f'Global Clustering: {round(global_clustering,4)}')\n",
    "\n",
    "# This is for only the LCC\n",
    "global_clustering_lcc = bipartite.robins_alexander_clustering(G0)\n",
    "print(f'Global Clustering LCC: {round(global_clustering_lcc, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-mason",
   "metadata": {},
   "source": [
    "# Nodes stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-reach",
   "metadata": {},
   "source": [
    "### *Betweenness centrality:* total number of paths that can pass through a node â€“ excluding the ones for which it is the origin or the destination; how many paths would become longer if node v would disappear from the network?\n",
    "    The pattern of betweenness centrality between the LCC and the entire network is very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Whole network\n",
    "betweenness_centrality = bipartite.betweenness_centrality(G, top_nodes)\n",
    "\n",
    "# For the LCC\n",
    "betweenness_centrality_lcc = bipartite.betweenness_centrality(G0, top_nodes_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "ax1.set_title('Betweenness Centrality of Whole Network')\n",
    "ax2.set_title('Betweenness Centrality of LCC')\n",
    "ax1.hist(betweenness_centrality.values(), bins=10, log=True)\n",
    "ax2.hist(betweenness_centrality_lcc.values(), bins=10, log=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-xerox",
   "metadata": {},
   "source": [
    "### *Closeness centrality:* inverse average path length. The closer a node are on average to every other nodes, the more central it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Whole Network\n",
    "closeness_centrality = bipartite.closeness_centrality(G, top_nodes)\n",
    "\n",
    "# For the LCC\n",
    "closeness_centrality_lcc = bipartite.closeness_centrality(G0, top_nodes_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "ax1.set_title('Closeness Centrality of Whole Network')\n",
    "ax2.set_title('Closeness Centrality of LCC')\n",
    "ax1.hist(closeness_centrality.values(), bins=75)\n",
    "ax2.hist(closeness_centrality_lcc.values(), bins=75)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-truth",
   "metadata": {},
   "source": [
    "### *Avg degree:* average number of edges each node uses to connect to its neighbors. Depending on the number of nodes and the avg degree, we can have an idea of how connected or sparse our network is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Degree\n",
    "node_degree = bipartite.degrees(G, top_nodes)\n",
    "#print(node_degree[1]) # Maria: I don't understand the print structure\n",
    "# node_degree[1] is showing the people nodes, and their corresponding degree\n",
    "# node_degree[0] shows all the crime nodes, and their correponding degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People node with the most neighbors (Max left degree)\n",
    "node_neighbors = {n: len(set(G.neighbors(n))) for n in top_nodes}\n",
    "maxnode = max(node_neighbors, key = node_neighbors.get)\n",
    "print(maxnode, node_neighbors[maxnode])\n",
    "\n",
    "# People node in LCC with most neighbors\n",
    "node_neighbors_lcc = {n: len(set(G0.neighbors(n))) for n in top_nodes_lcc}\n",
    "maxnode_lcc = max(node_neighbors_lcc, key = node_neighbors_lcc.get)\n",
    "print(maxnode_lcc, node_neighbors_lcc[maxnode_lcc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime node with the most neighbors (Max right degree)\n",
    "node_neighbors = {n: len(set(G.neighbors(n))) for n in bottom_nodes}\n",
    "maxnode = max(node_neighbors, key = node_neighbors.get)\n",
    "print(maxnode, node_neighbors[maxnode])\n",
    "\n",
    "node_neighbors_lcc = {n: len(set(G0.neighbors(n))) for n in bottom_nodes_lcc}\n",
    "maxnode_lcc = max(node_neighbors_lcc, key = node_neighbors_lcc.get)\n",
    "print(maxnode_lcc, node_neighbors_lcc[maxnode_lcc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-match",
   "metadata": {},
   "source": [
    "# Degree Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-sacramento",
   "metadata": {},
   "source": [
    "## Some text explaining this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree Distribution of the Entire Network, Combining People and Crime Nodes\n",
    "dd = Counter(dict(G.degree).values())\n",
    "dd = pd.DataFrame(list(dd.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "\n",
    "# Degree Distribution of the LCC, Combining People and Crime Nodes\n",
    "dd_lcc = Counter(dict(G0.degree).values())\n",
    "dd_lcc = pd.DataFrame(list(dd_lcc.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,10)) \n",
    "dd.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[0,0], color = \"#e41a1c\", title=\"Degree Distribution of All Nodes\")\n",
    "dd.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[0,1], color = \"#e41a1c\", loglog = True, title=\"Loglog Degree Distribution of All Nodes\")\n",
    "\n",
    "dd_lcc.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[1,0], color = \"#e41a1c\", title=\"Degree Distribution of LCC\")\n",
    "dd_lcc.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[1,1], color = \"#e41a1c\", loglog = True, title=\"Loglog Degree Distribution of LCC\")\n",
    "#plt.savefig(\"../Report/degree_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-absolute",
   "metadata": {},
   "source": [
    "## People Vs Crime Node Degree Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-respondent",
   "metadata": {},
   "source": [
    "## Some text explaining this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire graph\n",
    "e_p = []\n",
    "e_c = []\n",
    "for k in G.nodes(): # Loop through all nodes\n",
    "    if G.nodes[k][\"bipartite\"] == 0: # If People Nodes\n",
    "        e_p.append(len(G.edges(k)))  # Append number of edges to each node\n",
    "    else:                            # If Crime Nodes\n",
    "        e_c.append(len(G.edges(k)))  # Append number of edges to each crime\n",
    "\n",
    "e_cc = Counter(e_c)\n",
    "e_pp = Counter(e_p)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(12,10))\n",
    "fig.suptitle('Degree Distributions of the Network')\n",
    "\n",
    "ax1.scatter(e_cc.keys(), e_cc.values())\n",
    "ax1.set_title('Crime Nodes')\n",
    "ax1.set_xlabel('Degree')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "ax2.scatter(e_pp.keys(), e_pp.values())\n",
    "ax2.set_title('People Nodes')\n",
    "ax2.set_xlabel('Degree')\n",
    "ax2.set_ylabel('Count');\n",
    "\n",
    "# This only deals with the LCC\n",
    "# Lists of number of edges per node\n",
    "e_p1 = [] # Number of edges connected to each People node\n",
    "e_c1 = [] # Number of edges connected to each Crime node\n",
    "for k in G0.nodes(): # loop through all nodes\n",
    "    if G0.nodes[k][\"bipartite\"] == 0:  # If People Node\n",
    "        e_p1.append(len(G0.edges(k)))  # Append number of edges to each node\n",
    "    else:                              # If Crime Node\n",
    "        e_c1.append(len(G0.edges(k)))  # Append number of edges to each node\n",
    "\n",
    "e_cc1 = Counter(e_c1)\n",
    "e_pp1 = Counter(e_p1)\n",
    "\n",
    "#fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,4))\n",
    "#fig.suptitle('Degree Distributions of the Largest Connected Component')\n",
    "\n",
    "ax3.scatter(e_cc1.keys(), e_cc1.values())\n",
    "ax3.set_title('Crime Nodes of LCC')\n",
    "ax3.set_xlabel('Degree')\n",
    "ax3.set_ylabel('Count')\n",
    "\n",
    "ax4.scatter(e_pp1.keys(), e_pp1.values())\n",
    "ax4.set_title('People Nodes of LCC')\n",
    "ax4.set_xlabel('Degree')\n",
    "ax4.set_ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-commerce",
   "metadata": {},
   "source": [
    "# CCDF\n",
    "## *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Degree distribution\n",
    "ccdf = dd.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "ccdf[\"cumsum\"] = ccdf[\"Frequency\"].cumsum()\n",
    "ccdf[\"ccdf: P(X>=d)\"] = ccdf[\"cumsum\"] / ccdf[\"Frequency\"].sum()\n",
    "ccdf = ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")\n",
    "\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True)\n",
    "#plt.savefig(\"../Report/degree_distribution_ccdf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-father",
   "metadata": {},
   "source": [
    "## Fit CCDF to PowerLaw\n",
    "## *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcdf = np.log10(ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]])\n",
    "slope, log10intercept, r_value, p_value, std_err = linregress(logcdf[\"Degree (d)\"], logcdf[\"ccdf: P(X>=d)\"])\n",
    "print(\"CCDF Fit: %1.4f x ^ %1.4f (R2 = %1.4f, p = %1.4f)\" % (10 ** log10intercept, slope, r_value ** 2, p_value))\n",
    "print(\"\\n\")\n",
    "\n",
    "results = pl.Fit(ccdf[\"ccdf: P(X>=d)\"])\n",
    "k_min = ccdf[ccdf[\"ccdf: P(X>=d)\"] == results.power_law.xmin][\"Degree (d)\"]\n",
    "print(\"Powerlaw CCDF Fit: %1.4f x ^ -%1.4f (k_min = %d)\" % (10 ** results.power_law.Kappa, results.power_law.alpha, k_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best fit.\n",
    "ccdf[\"fit\"] = (10 ** results.power_law.Kappa) * (ccdf[\"Degree (d)\"] ** -results.power_law.alpha)\n",
    "ax = plt.gca()\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_fit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-warning",
   "metadata": {},
   "source": [
    "## More Powerlaw Stuff\n",
    "### *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(log_f, ccdf[\"Degree (d)\"], np.log10(ccdf[\"ccdf: P(X>=d)\"]), p0 = (1, 1))\n",
    "ccdf[\"fit\"] = ccdf.apply(lambda x: fu(x[\"Degree (d)\"], popt[0], popt[1]), axis = 1)\n",
    "\n",
    "ax = plt.gca()\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_fit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-portable",
   "metadata": {},
   "source": [
    "# Degree Distributions Per Node for Entire Network\n",
    "## *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "\n",
    "# Dictionary of Crime Nodes and Their Degree\n",
    "crimes_degree = list(G.degree(b))\n",
    "crimes_degree = pd.DataFrame(crimes_degree, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Dictionary of Crime Node Degrees and Their Frequencies\n",
    "crimes_degree_count = Counter(dict(G.degree(b)).values())\n",
    "crimes_degree_count = pd.DataFrame(list(crimes_degree_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "\n",
    "# Dictionary of People Nodes and Their Degree\n",
    "ppl_degree = list(G.degree(a))\n",
    "ppl_degree = pd.DataFrame(ppl_degree, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Dictionary of People Node Degrees and Their Frequencies\n",
    "ppl_degree_count = Counter(dict(G.degree(a)).values())\n",
    "ppl_degree_count = pd.DataFrame(list(ppl_degree_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#ppl_degree_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax = plt.gca()\n",
    "crimes_degree_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=200)\n",
    "ppl_degree_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=200)\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.xticks(np.arange(0, 26, step=1))\n",
    "plt.title(\"Degree Distributions per Node Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-toolbox",
   "metadata": {},
   "source": [
    "# Degree Distribution Using only the LCC\n",
    "## *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of People Nodes and their Degree\n",
    "p_deg_lcc = list(G0.degree(a))\n",
    "p_deg_lcc = pd.DataFrame(p_deg_lcc, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# DataFrame of People Node Degrees and their Frequency\n",
    "p_deg_lcc_count = Counter(dict(G0.degree(a)).values())\n",
    "p_deg_lcc_count = pd.DataFrame(list(p_deg_lcc_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#p_deg_lcc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of Crime Nodes and their Degree\n",
    "c_deg_lcc = list(G0.degree(b))\n",
    "c_deg_lcc = pd.DataFrame(c_deg_lcc, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Create DataFrame of Crime Node Degrees and their Frequency\n",
    "c_deg_lcc_count = Counter(dict(G0.degree(b)).values())\n",
    "c_deg_lcc_count = pd.DataFrame(list(c_deg_lcc_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#crimes_degree_lcc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Uses Only the LCC\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax = plt.gca()\n",
    "c_deg_lcc_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=150)\n",
    "p_deg_lcc_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=150)\n",
    "\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.xticks(np.arange(0, 26, step=1))\n",
    "plt.title(\"Degree Distributions per Node Category Using Only LCC\")\n",
    "#plt.savefig(\"../Report/degree_distribution_lcc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Uses Only the LCC\n",
    "fig, ax = plt.subplots(figsize=(8,5)) \n",
    "ax = plt.gca()\n",
    "c_deg_lcc_count.plot(kind = \"scatter\", loglog=True, x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=150)\n",
    "p_deg_lcc_count.plot(kind = \"scatter\", loglog=True, x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=150)\n",
    "\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.title(\"Degree Distributions per Node Category Using Only LCC\")\n",
    "#plt.savefig(\"../Report/degree_distribution_loglog_lcc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree distribution of Both Nodes in LCC\n",
    "ccdf_lcc = dd_lcc.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "ccdf_lcc[\"cumsum\"] = ccdf_lcc[\"Frequency\"].cumsum()\n",
    "ccdf_lcc[\"ccdf: P(X>=d)\"] = ccdf_lcc[\"cumsum\"] / ccdf_lcc[\"Frequency\"].sum()\n",
    "ccdf_lcc = ccdf_lcc[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime Degree Distribution Using Only LCC\n",
    "c_ccdf = c_deg_lcc_count.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "c_ccdf[\"cumsum\"] = c_ccdf[\"Frequency\"].cumsum()\n",
    "c_ccdf[\"ccdf: P(X>=d)\"] = c_ccdf[\"cumsum\"] / c_ccdf[\"Frequency\"].sum()\n",
    "c_ccdf = c_ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People Degree Distribution Using Only LCC\n",
    "p_ccdf = p_deg_lcc_count.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "p_ccdf[\"cumsum\"] = p_ccdf[\"Frequency\"].cumsum()\n",
    "p_ccdf[\"ccdf: P(X>=d)\"] = p_ccdf[\"cumsum\"] / p_ccdf[\"Frequency\"].sum()\n",
    "p_ccdf = p_ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12,4)) \n",
    "ax = plt.gca()\n",
    "\n",
    "c_ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[0], color = \"#fb00ff\", loglog = True)\n",
    "p_ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[0], color = \"#ff9d00\", loglog = True)\n",
    "axs[0].legend([\"Crimes\",\"People\"])\n",
    "axs[0].set_title(\"CCDF per Node Category Using Only LCC\")\n",
    "\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[1], color = \"r\", loglog = True)\n",
    "axs[1].legend([\"Both Nodes Combined\"])\n",
    "axs[1].set_title(\"CCDF For All Nodes in LCC\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-rover",
   "metadata": {},
   "source": [
    "# Fit CCDF for LCC to PowerLaw\n",
    "## *Explanation*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcdf_lcc = np.log10(ccdf_lcc[[\"Degree (d)\", \"ccdf: P(X>=d)\"]])\n",
    "slope, log10intercept, r_value, p_value, std_err = linregress(logcdf_lcc[\"Degree (d)\"], logcdf_lcc[\"ccdf: P(X>=d)\"])\n",
    "print(\"CCDF Fit: %1.4f x ^ %1.4f (R2 = %1.4f, p = %1.4f)\" % (10 ** log10intercept, slope, r_value ** 2, p_value))\n",
    "print(\"\\n\")\n",
    "\n",
    "results = pl.Fit(ccdf_lcc[\"ccdf: P(X>=d)\"])\n",
    "k_min = ccdf_lcc[ccdf_lcc[\"ccdf: P(X>=d)\"] == results.power_law.xmin][\"Degree (d)\"]\n",
    "print(\"Powerlaw CCDF Fit: %1.4f x ^ -%1.4f (k_min = %d)\" % (10 ** results.power_law.Kappa, results.power_law.alpha, k_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best fit.\n",
    "ccdf_lcc[\"fit\"] = (10 ** results.power_law.Kappa) * (ccdf_lcc[\"Degree (d)\"] ** -results.power_law.alpha)\n",
    "ax = plt.gca()\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_lcc_fit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-explosion",
   "metadata": {},
   "source": [
    "# Projected Plots of the Entire Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Entire Network of People\n",
    "P = bipartite.weighted_projected_graph(G, top_nodes)\n",
    "nx.draw(P, node_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Entire Network of Crimes\n",
    "C = bipartite.weighted_projected_graph(G, bottom_nodes)\n",
    "nx.draw(C, node_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-going",
   "metadata": {},
   "source": [
    "# Plots of Largest Connected Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only biggest component\n",
    "pos = nx.spring_layout(G0)\n",
    "posB = nx.bipartite_layout(G0, top_nodes)\n",
    "biggest_comp_graph = nx.draw(G0,pos,node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-redhead",
   "metadata": {},
   "source": [
    "## Projected Graphs From Only the LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the People from the LCC\n",
    "P = bipartite.weighted_projected_graph(G0, top_nodes_lcc)\n",
    "nx.draw(P, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Crimes from the LCC\n",
    "C = bipartite.weighted_projected_graph(G0, bottom_nodes_lcc)\n",
    "nx.draw(C, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest component bipartite plot\n",
    "biggest_comp_graph = nx.draw(G0,posB,node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-indie",
   "metadata": {},
   "source": [
    "## Non-square adjacency matrix, and stocastic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-square adjacency matrix\n",
    "adjmat = nx.algorithms.bipartite.matrix.biadjacency_matrix(G, top_nodes)\n",
    "print(adjmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project along smaller axis\n",
    "if adjmat.shape[0] == 551:\n",
    "    adjmat_proj = adjmat.dot(adjmat.T)\n",
    "else:\n",
    "    adjmat_proj = adjmat.T.dot(adjmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make stocastic\n",
    "adjmat_proj_stoc = adjmat_proj / adjmat_proj.sum(axis = 1)\n",
    "print(adjmat_proj_stoc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-albert",
   "metadata": {},
   "source": [
    "# Projections of suspect graph\n",
    " Projections of suspect graph  \n",
    " From the BCC extracted only the suspect edges and created a new graph that is not connected but still bipartite. From there projected onto people nodes.\n",
    "- [ ] Figure out how to keep crime name as edge attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-occasions",
   "metadata": {},
   "source": [
    "## Extract suspect edges\n",
    "Created a new graph with only suspects to do further analysis (try projections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected just the suspect edges\n",
    "suspect_edges = [(p,c) for p,c,e in G0.edges(data=True) if e['role'] == 'Suspect']\n",
    "#print(suspect_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all nodes that have suspect edges\n",
    "sus_nodes = pd.DataFrame(suspect_edges, columns=['node', 'crime']).iloc[:,0].unique()\n",
    "sus_nodes = set(sus_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-science",
   "metadata": {},
   "source": [
    "## Suspect subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS = G0.edge_subgraph(suspect_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Num. of nodes: {} \\nNum. of edges: {} \\nIs bipartite? {} \\nIs connected? {}'.format(\n",
    "        GS.number_of_nodes(), \n",
    "        GS.number_of_edges(), \n",
    "        nx.is_bipartite(GS),\n",
    "        nx.is_connected(GS)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-angel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx.draw(GS,pos,node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-distribution",
   "metadata": {},
   "source": [
    "## Projection on to suspect nodes (people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_bipartite(GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the people and crime nodes\n",
    "people_nodes_GS = {n for n, d in GS.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "crime_nodes_GS = set(GS) - people_nodes_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection of suspect graph\n",
    "weighted_suspect_graph = nx.bipartite.weighted_projected_graph(GS, people_nodes_GS, ratio=False)\n",
    "list(weighted_suspect_graph.edges(data=True))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the number of shared neighbors\n",
    "weights = list(nx.get_edge_attributes(weighted_suspect_graph, 'weight').values())\n",
    "\n",
    "# plot weights\n",
    "plt.hist(weights, bins = 10, log=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82a91a22060084f3e8dbe72ba49a002eddd687e7ed0e7d249946fe1b995c1ddc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
