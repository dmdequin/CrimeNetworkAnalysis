{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intelligent-instrument",
   "metadata": {},
   "source": [
    "# Network Analysis Project\n",
    "## Crime Network Analysis\n",
    "Professor: Michele Coscia\n",
    "\n",
    "This notebook contains all of the code developed for the Network Analysis Course at ITU. We will be using...**finish**\n",
    "\n",
    "**Add Description**\n",
    "\n",
    "Group 10:  \n",
    "Carl August Wismer ([cwis@itu.dk](mailto:cwis@itu.dk))  <br>\n",
    "Crisanna Cornish ([ccor@itu.dk](mailto:ccor@itu.dk))  <br>\n",
    "Danielle Dequin ([ddeq@itu.dk](mailto:ddeq@itu.dk))  <br>\n",
    "Maria Do Carmo Madeira Santos Silva Passos de Sousa ([mdom@itu.dk](mailto:mdom@itu.dk))  <br>\n",
    "Moneeca Abru Iftikhar Latif ([abml@itu.dk](mailto:abml@itu.dk))  <br>\n",
    "Sabrina Fonseca Pereira ([sabf@itu.dk](mailto:sabf@itu.dk))  <br>\n",
    "\n",
    "Created: 27-09-2021  \n",
    "Last Modified: 19-11-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-digest",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "The data are a network of associations among suspects, victims, and/or witnesses involved in crimes in St. Louis in the 1990s. Data are derived from police records, via snowball sampling from five initial homicides. Left nodes are people, right nodes are crime events, and edges connect people to particular crimes events they were associated with. Metadata includes names, genders, and roles (suspects, victims, and/or witnesses).\n",
    "\n",
    "This is an undirected, unweighted, bipartite network with 1380 nodes and 1476 edges.\n",
    "\n",
    "Data can be downloaded [here](http://konect.cc/networks/moreno_crime/) or [here](https://networks.skewed.de/net/crime)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-sailing",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "import powerlaw as pl\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-stationery",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../Data/out.moreno_crime_crime'\n",
    "ROLE = '../Data/rel.moreno_crime_crime.person.role'\n",
    "NAME = '../Data/ent.moreno_crime_crime.person.name'\n",
    "SEX =  '../Data/ent.moreno_crime_crime.person.sex'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-three",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-penguin",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, l):\n",
    "    \"\"\"A custom function which is a power law with its exponential truncation. From 'Atlas for the Aspiring\n",
    "    Network Scientist' Chapter 6\n",
    "    \"\"\"\n",
    "    return (x ** a) * np.exp(-l * x) \n",
    "\n",
    "def log_f(x, a, l):\n",
    "    \"\"\"The Logarithm of f, used to fit the log of the CCDF using curve_fit\"\"\"\n",
    "    return np.log10(f(x, a, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-complex",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA) as f:\n",
    "    data = f.read().splitlines()\n",
    "    \n",
    "with open(ROLE) as f:\n",
    "    role = f.read().splitlines()\n",
    "    \n",
    "with open(NAME) as f:\n",
    "    name = f.read().splitlines()\n",
    "    \n",
    "with open(SEX) as f:\n",
    "    sex = f.read().splitlines()\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    data[i] = 'p' + data[i] # adds 'p' to the People nodes to differentiate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.read_edgelist(data) # read edgelist in\n",
    "print(len(B.nodes()), len(B.edges())) # sanity check (1380, 1476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(DATA, dtype=str)\n",
    "a = np.unique(graph[:,0]) # people nodes\n",
    "b = np.unique(graph[:,1]) # crime nodes\n",
    "a = ['p' + a for a in a] # add string to differentiate\n",
    "\n",
    "print(f\"There are {len(a)} unique people and {len(b)} unique crime events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-groove",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "for j in range(len(a)):\n",
    "    G.add_node(a[j], bipartite=0, data=True, name=name[j], sex=sex[j]) # Add attributes name and sex\n",
    "\n",
    "G.add_nodes_from(b, bipartite=1, data=True)\n",
    "\n",
    "# add edges\n",
    "i = 0\n",
    "for edge in B.edges():\n",
    "    G.add_edge(edge[0], edge[1], role= [role[i]])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(\n",
    "    'Num. of nodes: {} \\nNum. of edges: {} \\nIs bipartite? {} \\nIs connected? {}'.format(\n",
    "        G.number_of_nodes(), \n",
    "        G.number_of_edges(), \n",
    "        nx.is_bipartite(G),\n",
    "        nx.is_connected(G)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-competition",
   "metadata": {},
   "source": [
    "From the [official Networkx docs](https://networkx.org/documentation/stable/reference/algorithms/bipartite.html):\n",
    "\n",
    "Many algorithms of the bipartite module of NetworkX require, as an argument, a container with all the nodes that belong to one set, in addition to the bipartite graph B. The functions in the bipartite package do not check that the node set is actually correct nor that the input graph is actually bipartite. If B is connected, you can find the two node sets using a two-coloring algorithm:\n",
    "\n",
    "```py\n",
    ">>> nx.is_connected(B)\n",
    "True\n",
    ">>> bottom_nodes, top_nodes = bipartite.sets(B)\n",
    "```\n",
    "However, if the input graph is not connected, there are more than one possible colorations. This is the reason why we require the user to pass a container with all nodes of one bipartite node set as an argument to most bipartite functions. In the face of ambiguity, we refuse the temptation to guess and raise an AmbiguousSolution Exception if the input graph for bipartite.sets is disconnected.\n",
    "\n",
    "Using the bipartite node attribute, you can easily get the two node sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0} # people\n",
    "bottom_nodes = set(G) - top_nodes      # crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-discrimination",
   "metadata": {},
   "source": [
    "## Adding Metadata to Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.get_node_attributes(G, 'name')['p1']) # check name of person 'p1' = 'AbelDennis'\n",
    "print(nx.get_node_attributes(G, 'sex')['p1']) # check sex of person 'p1' = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_edge_attributes(G, 'role')['p1', '1']\n",
    "# check role of edge between person p1 and crime 1 = 'Suspect'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-efficiency",
   "metadata": {},
   "source": [
    "### Add \"Criminal Status\" node attribute to each people node\n",
    "\n",
    "**Here, we are making the assumption that, if a person has been involved in a crime as a \"suspect\" or \"victim suspect\" then they are a criminal. Meanwhile, if someone has only been a \"witness\" or a \"victim\" then they are \"innocent\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_edge_attributes(G, 'role')\n",
    "\n",
    "# Initialize a dictionary based on people nodes to keep track of all roles per node\n",
    "p_nodes = {el:[] for el in top_nodes}\n",
    "\n",
    "# Add all the edge attributes to a dictionary of people nodes\n",
    "for key,value in nx.get_edge_attributes(G, 'role').items():\n",
    "    for part in key:\n",
    "        if part in top_nodes:\n",
    "            p_nodes[part].append(value[0])\n",
    "print(p_nodes['p1'])\n",
    "\n",
    "# Initialize a dictionary to keep track of who is a \"criminal\"\n",
    "criminals = {el:[] for el in top_nodes}\n",
    "\n",
    "# Loop through all roles per node, and deem them criminals if ever they have been a suspect\n",
    "for key in p_nodes:\n",
    "    for value in p_nodes[key]:\n",
    "        if value == \"Suspect\":\n",
    "            criminals[key] = \"Criminal\"\n",
    "        elif value == \"Victim Suspect\":\n",
    "            criminals[key] = \"Criminal\"\n",
    "        else:\n",
    "            criminals[key] = \"Innocent\"\n",
    "\n",
    "print(criminals['p1'])\n",
    "\n",
    "# Convert to pandas df\n",
    "criminals_df = pd.DataFrame(criminals.items(), columns=['node', 'Criminal_Status'])\n",
    "\n",
    "# loop through rows in the data frame and add the attribute of Criminal Status\n",
    "for index, row in criminals_df.iterrows():\n",
    "    #print(row['node'])\n",
    "    G.nodes[row['node']]['Criminal_Status'] = row['Criminal_Status']\n",
    "\n",
    "print(nx.get_node_attributes(G, 'Criminal_Status')['p1']) # check name of person 'p1' = 'Criminal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-rocket",
   "metadata": {},
   "source": [
    "# Finding Largest Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components in the graph sorted in descendent order\n",
    "Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "\n",
    "# Selecting the biggest component\n",
    "G0 = G.subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of nodes for the LCC\n",
    "top_nodes_lcc = {n for n, d in G0.nodes(data=True) if d[\"bipartite\"] == 0} # people\n",
    "bottom_nodes_lcc = set(G0) - top_nodes_lcc      # crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nodes for each component and number of components\n",
    "comp_list = []\n",
    "for comp in Gcc:\n",
    "    comp_len = len(comp)\n",
    "    comp_list.append(comp_len)\n",
    "\n",
    "f'Number of nodes for each components {comp_list} and number of components {len(comp_list)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-demographic",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-hacker",
   "metadata": {},
   "source": [
    "### Average Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Density: {} \\nAverage Clustering: {}'.format(\n",
    "        round(bipartite.density(G, bottom_nodes),5), \n",
    "        round(bipartite.average_clustering(G),5)\n",
    "    )\n",
    ")\n",
    "print('\\n')\n",
    "print('Density LCC: {} \\nAverage Clustering LCC: {}'.format(\n",
    "        round(bipartite.density(G0, bottom_nodes_lcc),5), \n",
    "        round(bipartite.average_clustering(G0),5)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-narrative",
   "metadata": {},
   "source": [
    "### Another way to get Average Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = bipartite.clustering(G)\n",
    "print(f'Clustering of Entire Network: {round(sum(cluster.values())/len(cluster.values()),5)}')\n",
    "\n",
    "cluster2 = bipartite.clustering(G0)\n",
    "print(f'Clustering for LCC: {round(sum(cluster2.values())/len(cluster2.values()),5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-stewart",
   "metadata": {},
   "source": [
    "### Global Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entire graph\n",
    "global_clustering = bipartite.robins_alexander_clustering(G)\n",
    "print(f'Global Clustering: {round(global_clustering,5)}')\n",
    "\n",
    "# This is for only the LCC\n",
    "global_clustering_lcc = bipartite.robins_alexander_clustering(G0)\n",
    "print(f'Global Clustering LCC: {round(global_clustering_lcc, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-leeds",
   "metadata": {},
   "source": [
    "**EXPLANATION OF CLUSTERING:** TO BE DONE BY SOMEONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-pulse",
   "metadata": {},
   "source": [
    "# Nodes stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-orchestra",
   "metadata": {},
   "source": [
    "## Betweenneess Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Whole network\n",
    "betweenness_centrality = bipartite.betweenness_centrality(G, top_nodes)\n",
    "\n",
    "# For the LCC\n",
    "betweenness_centrality_lcc = bipartite.betweenness_centrality(G0, top_nodes_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "ax1.set_title('Betweenness Centrality of Whole Network')\n",
    "ax2.set_title('Betweenness Centrality of LCC')\n",
    "ax1.hist(betweenness_centrality.values(), bins=10, log=True)\n",
    "ax2.hist(betweenness_centrality_lcc.values(), bins=10, log=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-worker",
   "metadata": {},
   "source": [
    "## Closeness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Whole Network\n",
    "closeness_centrality = bipartite.closeness_centrality(G, top_nodes)\n",
    "\n",
    "# For the LCC\n",
    "closeness_centrality_lcc = bipartite.closeness_centrality(G0, top_nodes_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "ax1.set_title('Closeness Centrality of Whole Network')\n",
    "ax2.set_title('Closeness Centrality of LCC')\n",
    "ax1.hist(closeness_centrality.values(), bins=75)\n",
    "ax2.hist(closeness_centrality_lcc.values(), bins=75)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People node with the most neighbors (Max left degree)\n",
    "node_neighbors = {n: len(set(G.neighbors(n))) for n in top_nodes}\n",
    "maxnode = max(node_neighbors, key = node_neighbors.get)\n",
    "print(maxnode, node_neighbors[maxnode])\n",
    "\n",
    "# People node in LCC with most neighbors\n",
    "node_neighbors_lcc = {n: len(set(G0.neighbors(n))) for n in top_nodes_lcc}\n",
    "maxnode_lcc = max(node_neighbors_lcc, key = node_neighbors_lcc.get)\n",
    "print(maxnode_lcc, node_neighbors_lcc[maxnode_lcc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime node with the most neighbors (Max right degree)\n",
    "node_neighbors = {n: len(set(G.neighbors(n))) for n in bottom_nodes}\n",
    "maxnode = max(node_neighbors, key = node_neighbors.get)\n",
    "print(maxnode, node_neighbors[maxnode])\n",
    "\n",
    "node_neighbors_lcc = {n: len(set(G0.neighbors(n))) for n in bottom_nodes_lcc}\n",
    "maxnode_lcc = max(node_neighbors_lcc, key = node_neighbors_lcc.get)\n",
    "print(maxnode_lcc, node_neighbors_lcc[maxnode_lcc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-record",
   "metadata": {},
   "source": [
    "**ADD EXPLANATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-there",
   "metadata": {},
   "source": [
    "## Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree Distribution of the Entire Network, Combining People and Crime Nodes\n",
    "dd = Counter(dict(G.degree).values())\n",
    "dd = pd.DataFrame(list(dd.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "\n",
    "# Degree Distribution of the LCC, Combining People and Crime Nodes\n",
    "dd_lcc = Counter(dict(G0.degree).values())\n",
    "dd_lcc = pd.DataFrame(list(dd_lcc.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,10)) \n",
    "dd.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[0,0], color = \"#e41a1c\", title=\"Degree Distribution of All Nodes\")\n",
    "dd.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[0,1], color = \"#e41a1c\", loglog = True, title=\"Loglog Degree Distribution of All Nodes\")\n",
    "\n",
    "dd_lcc.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[1,0], color = \"#e41a1c\", title=\"Degree Distribution of LCC\")\n",
    "dd_lcc.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", ax=axs[1,1], color = \"#e41a1c\", loglog = True, title=\"Loglog Degree Distribution of LCC\")\n",
    "#plt.savefig(\"../Report/degree_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-planning",
   "metadata": {},
   "source": [
    "## People VS Crime Node Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire graph\n",
    "e_p = []\n",
    "e_c = []\n",
    "for k in G.nodes(): # Loop through all nodes\n",
    "    if G.nodes[k][\"bipartite\"] == 0: # If People Nodes\n",
    "        e_p.append(len(G.edges(k)))  # Append number of edges to each node\n",
    "    else:                            # If Crime Nodes\n",
    "        e_c.append(len(G.edges(k)))  # Append number of edges to each crime\n",
    "\n",
    "e_cc = Counter(e_c)\n",
    "e_pp = Counter(e_p)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(12,10))\n",
    "fig.suptitle('Degree Distributions of the Network')\n",
    "\n",
    "ax1.scatter(e_cc.keys(), e_cc.values())\n",
    "ax1.set_title('Crime Nodes')\n",
    "ax1.set_xlabel('Degree')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "ax2.scatter(e_pp.keys(), e_pp.values())\n",
    "ax2.set_title('People Nodes')\n",
    "ax2.set_xlabel('Degree')\n",
    "ax2.set_ylabel('Count');\n",
    "\n",
    "# This only deals with the LCC\n",
    "# Lists of number of edges per node\n",
    "e_p1 = [] # Number of edges connected to each People node\n",
    "e_c1 = [] # Number of edges connected to each Crime node\n",
    "for k in G0.nodes(): # loop through all nodes\n",
    "    if G0.nodes[k][\"bipartite\"] == 0:  # If People Node\n",
    "        e_p1.append(len(G0.edges(k)))  # Append number of edges to each node\n",
    "    else:                              # If Crime Node\n",
    "        e_c1.append(len(G0.edges(k)))  # Append number of edges to each node\n",
    "\n",
    "e_cc1 = Counter(e_c1)\n",
    "e_pp1 = Counter(e_p1)\n",
    "\n",
    "#fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,4))\n",
    "#fig.suptitle('Degree Distributions of the Largest Connected Component')\n",
    "\n",
    "ax3.scatter(e_cc1.keys(), e_cc1.values())\n",
    "ax3.set_title('Crime Nodes of LCC')\n",
    "ax3.set_xlabel('Degree')\n",
    "ax3.set_ylabel('Count')\n",
    "\n",
    "ax4.scatter(e_pp1.keys(), e_pp1.values())\n",
    "ax4.set_title('People Nodes of LCC')\n",
    "ax4.set_xlabel('Degree')\n",
    "ax4.set_ylabel('Count');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-aquarium",
   "metadata": {},
   "source": [
    "## CCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Degree distribution\n",
    "ccdf = dd.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "ccdf[\"cumsum\"] = ccdf[\"Frequency\"].cumsum()\n",
    "ccdf[\"ccdf: P(X>=d)\"] = ccdf[\"cumsum\"] / ccdf[\"Frequency\"].sum()\n",
    "ccdf = ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")\n",
    "\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True)\n",
    "#plt.savefig(\"../Report/degree_distribution_ccdf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-venice",
   "metadata": {},
   "source": [
    "## Fit CCDF to PowerLaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcdf = np.log10(ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]])\n",
    "slope, log10intercept, r_value, p_value, std_err = linregress(logcdf[\"Degree (d)\"], logcdf[\"ccdf: P(X>=d)\"])\n",
    "print(\"CCDF Fit: %1.4f x ^ %1.4f (R2 = %1.4f, p = %1.4f)\" % (10 ** log10intercept, slope, r_value ** 2, p_value))\n",
    "print(\"\\n\")\n",
    "\n",
    "results = pl.Fit(ccdf[\"ccdf: P(X>=d)\"])\n",
    "k_min = ccdf[ccdf[\"ccdf: P(X>=d)\"] == results.power_law.xmin][\"Degree (d)\"]\n",
    "print(\"Powerlaw CCDF Fit: %1.4f x ^ -%1.4f (k_min = %d)\" % (10 ** results.power_law.Kappa, results.power_law.alpha, k_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best fit.\n",
    "ccdf[\"fit\"] = (10 ** results.power_law.Kappa) * (ccdf[\"Degree (d)\"] ** -results.power_law.alpha)\n",
    "ax = plt.gca()\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_fit.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-headquarters",
   "metadata": {},
   "source": [
    "## Degree Distributions Per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "\n",
    "# Dictionary of Crime Nodes and Their Degree\n",
    "crimes_degree = list(G.degree(b))\n",
    "crimes_degree = pd.DataFrame(crimes_degree, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Dictionary of Crime Node Degrees and Their Frequencies\n",
    "crimes_degree_count = Counter(dict(G.degree(b)).values())\n",
    "crimes_degree_count = pd.DataFrame(list(crimes_degree_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-bankruptcy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "\n",
    "# Dictionary of People Nodes and Their Degree\n",
    "ppl_degree = list(G.degree(a))\n",
    "ppl_degree = pd.DataFrame(ppl_degree, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Dictionary of People Node Degrees and Their Frequencies\n",
    "ppl_degree_count = Counter(dict(G.degree(a)).values())\n",
    "ppl_degree_count = pd.DataFrame(list(ppl_degree_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#ppl_degree_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes the entire network\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax = plt.gca()\n",
    "crimes_degree_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=200)\n",
    "ppl_degree_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=200)\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.xticks(np.arange(0, 26, step=1))\n",
    "plt.title(\"Degree Distributions per Node Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-processor",
   "metadata": {},
   "source": [
    "## Projected Plots of the Entire Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Entire Network of People\n",
    "P = bipartite.weighted_projected_graph(G, top_nodes)\n",
    "nx.draw(P, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire Network of Crimes\n",
    "C = bipartite.weighted_projected_graph(G, bottom_nodes)\n",
    "nx.draw(C, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only biggest component\n",
    "pos = nx.spring_layout(G0)\n",
    "posB = nx.bipartite_layout(G0, top_nodes)\n",
    "biggest_comp_graph = nx.draw(G0, pos, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest component bipartite plot\n",
    "biggest_comp_graph = nx.draw(G0, posB, node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-joint",
   "metadata": {},
   "source": [
    "## Projected Graphs from only the LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the People from the LCC\n",
    "P = bipartite.weighted_projected_graph(G0, top_nodes_lcc)\n",
    "nx.draw(P, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Crimes from the LCC\n",
    "C = bipartite.weighted_projected_graph(G0, bottom_nodes_lcc)\n",
    "nx.draw(C, node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-feature",
   "metadata": {},
   "source": [
    "## Degree Distribution Using only the LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of People Nodes and their Degree\n",
    "p_deg_lcc = list(G0.degree(a))\n",
    "p_deg_lcc = pd.DataFrame(p_deg_lcc, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# DataFrame of People Node Degrees and their Frequency\n",
    "p_deg_lcc_count = Counter(dict(G0.degree(a)).values())\n",
    "p_deg_lcc_count = pd.DataFrame(list(p_deg_lcc_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#p_deg_lcc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of Crime Nodes and their Degree\n",
    "c_deg_lcc = list(G0.degree(b))\n",
    "c_deg_lcc = pd.DataFrame(c_deg_lcc, columns = (\"Node\", \"Degree\")).sort_values(by = \"Node\")\n",
    "\n",
    "# Create DataFrame of Crime Node Degrees and their Frequency\n",
    "c_deg_lcc_count = Counter(dict(G0.degree(b)).values())\n",
    "c_deg_lcc_count = pd.DataFrame(list(c_deg_lcc_count.items()), columns = (\"Degree (d)\", \"Frequency\")).sort_values(by = \"Degree (d)\")\n",
    "#crimes_degree_lcc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Uses Only the LCC\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax = plt.gca()\n",
    "c_deg_lcc_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=150)\n",
    "p_deg_lcc_count.plot(kind = \"scatter\", x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=150)\n",
    "\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.xticks(np.arange(0, 26, step=1))\n",
    "plt.title(\"Degree Distributions per Node Category Using Only LCC\")\n",
    "#plt.savefig(\"../Report/degree_distribution_lcc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Uses Only the LCC\n",
    "fig, ax = plt.subplots(figsize=(8,5)) \n",
    "ax = plt.gca()\n",
    "c_deg_lcc_count.plot(kind = \"scatter\", loglog=True, x = \"Degree (d)\", y = \"Frequency\", color = \"#fb00ff\", ax = ax, alpha=0.9, s=150)\n",
    "p_deg_lcc_count.plot(kind = \"scatter\", loglog=True, x = \"Degree (d)\", y = \"Frequency\", color = \"#ff9d00\", ax = ax, alpha=0.7, s=150)\n",
    "\n",
    "ax.legend([\"Crimes\",\"People\"])\n",
    "plt.title(\"Degree Distributions per Node Category Using Only LCC\")\n",
    "#plt.savefig(\"../Report/degree_distribution_loglog_lcc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree distribution of Both Nodes in LCC\n",
    "ccdf_lcc = dd_lcc.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "ccdf_lcc[\"cumsum\"] = ccdf_lcc[\"Frequency\"].cumsum()\n",
    "ccdf_lcc[\"ccdf: P(X>=d)\"] = ccdf_lcc[\"cumsum\"] / ccdf_lcc[\"Frequency\"].sum()\n",
    "ccdf_lcc = ccdf_lcc[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime Degree Distribution Using Only LCC\n",
    "c_ccdf = c_deg_lcc_count.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "c_ccdf[\"cumsum\"] = c_ccdf[\"Frequency\"].cumsum()\n",
    "c_ccdf[\"ccdf: P(X>=d)\"] = c_ccdf[\"cumsum\"] / c_ccdf[\"Frequency\"].sum()\n",
    "c_ccdf = c_ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People Degree Distribution Using Only LCC\n",
    "p_ccdf = p_deg_lcc_count.sort_values(by = \"Degree (d)\", ascending = False)\n",
    "p_ccdf[\"cumsum\"] = p_ccdf[\"Frequency\"].cumsum()\n",
    "p_ccdf[\"ccdf: P(X>=d)\"] = p_ccdf[\"cumsum\"] / p_ccdf[\"Frequency\"].sum()\n",
    "p_ccdf = p_ccdf[[\"Degree (d)\", \"ccdf: P(X>=d)\"]].sort_values(by = \"Degree (d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12,4)) \n",
    "ax = plt.gca()\n",
    "\n",
    "c_ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[0], color = \"#fb00ff\", loglog = True)\n",
    "p_ccdf.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[0], color = \"#ff9d00\", loglog = True)\n",
    "axs[0].legend([\"Crimes\",\"People\"])\n",
    "axs[0].set_title(\"CCDF per Node Category Using Only LCC\")\n",
    "\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", ax=axs[1], color = \"r\", loglog = True)\n",
    "axs[1].legend([\"Both Nodes Combined\"])\n",
    "axs[1].set_title(\"CCDF For All Nodes in LCC\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-cheat",
   "metadata": {},
   "source": [
    "## Fit CCDF to PowerLaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcdf_lcc = np.log10(ccdf_lcc[[\"Degree (d)\", \"ccdf: P(X>=d)\"]])\n",
    "slope, log10intercept, r_value, p_value, std_err = linregress(logcdf_lcc[\"Degree (d)\"], logcdf_lcc[\"ccdf: P(X>=d)\"])\n",
    "print(\"CCDF Fit: %1.4f x ^ %1.4f (R2 = %1.4f, p = %1.4f)\" % (10 ** log10intercept, slope, r_value ** 2, p_value))\n",
    "print(\"\\n\")\n",
    "\n",
    "results = pl.Fit(ccdf_lcc[\"ccdf: P(X>=d)\"])\n",
    "k_min = ccdf_lcc[ccdf_lcc[\"ccdf: P(X>=d)\"] == results.power_law.xmin][\"Degree (d)\"]\n",
    "print(\"Powerlaw CCDF Fit: %1.4f x ^ -%1.4f (k_min = %d)\" % (10 ** results.power_law.Kappa, results.power_law.alpha, k_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best fit.\n",
    "ccdf_lcc[\"fit\"] = (10 ** results.power_law.Kappa) * (ccdf_lcc[\"Degree (d)\"] ** -results.power_law.alpha)\n",
    "ax = plt.gca()\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_lcc_fit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-center",
   "metadata": {},
   "source": [
    "# Adjacency Matrix\n",
    "\n",
    "Central Place Theory.\n",
    "Chapter 29 in the book.\n",
    "\n",
    "The Adjacency matrix of our LCC looks like a discrete model. Which imposes a strict core-periphery structure. This also does not seem to show any smaller communities extending off of the core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the degrees of the nodes\n",
    "degree = dict(G0.degree)\n",
    "\n",
    "# Figure out which node is of which type\n",
    "rows, cols = nx.algorithms.bipartite.sets(G0)\n",
    "\n",
    "# Sort rows and columns according to their degree\n",
    "rows = {n: degree[n] for n in rows}\n",
    "cols = {n: degree[n] for n in cols}\n",
    "rows = [n[0] for n in sorted(rows.items(), key = lambda x : x[1], reverse = True)]\n",
    "cols = [n[0] for n in sorted(cols.items(), key = lambda x : x[1], reverse = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the biadjacency matrix with the properly sorted rows and columns\n",
    "B = nx.algorithms.bipartite.matrix.biadjacency_matrix(G0, rows, column_order = cols)\n",
    "plt.figure(figsize=(4,8))\n",
    "plt.spy(B, markersize = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-pennsylvania",
   "metadata": {},
   "source": [
    "# Finding Which Nodes Connect to Which Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-partition",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_whole = nx.algorithms.core.core_number(G)\n",
    "c_whole_count = Counter(c_whole.values())\n",
    "c_whole_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nx.algorithms.core.core_number(G0)\n",
    "count_c = Counter(c.values())\n",
    "count_c\n",
    "print(f\"Core 1 has {count_c[1]} Nodes attached \\nCore 2 has {count_c[2]} Nodes \\nCore 3 has {count_c[3]} Nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-license",
   "metadata": {},
   "source": [
    "# Edge-Centric Plot\n",
    "\n",
    "Based on Exercise 27.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-seventh",
   "metadata": {},
   "source": [
    "https://www.networkatlas.eu/exercise.htm?c=27&e=1\n",
    "\n",
    "look for how to put a colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the degrees of the nodes\n",
    "degrees = dict(G0.degree)\n",
    "\n",
    "# Edge-centric plot\n",
    "edge_assort = [(degrees[e[0]], degrees[e[1]]) for e in G0.edges]\n",
    "edge_assort = pd.DataFrame(data = edge_assort, columns = (\"k1\", \"k2\"))\n",
    "edge_assort = edge_assort.groupby(by = [\"k1\", \"k2\"]).size().reset_index().rename(columns = {0: \"count\"}).sort_values(by = \"count\")\n",
    "\n",
    "# Taking the log count of edges with nodes with the same degrees\n",
    "edge_assort[\"count\"] = np.log(edge_assort[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the edge-centric plot\n",
    "ax = plt.gca()\n",
    "plt.scatter(edge_assort[\"k1\"], edge_assort[\"k2\"], c = edge_assort[\"count\"], cmap = \"Reds\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a new figure\n",
    "plt.clf()\n",
    "\n",
    "# Two vectors with the degree of a node in one, and the average neighbor degree in the other\n",
    "node_assort = [(degrees[n], degrees[n2]) for n in G0.nodes for n2 in G0.neighbors(n)]\n",
    "node_assort = pd.DataFrame(data = node_assort, columns = (\"k\", \"neigh_k\"))\n",
    "node_assort = node_assort.groupby(by = \"k\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the node-centric plot\n",
    "ax = plt.gca()\n",
    "plt.scatter(node_assort[\"k\"], node_assort[\"neigh_k\"])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make two vectors with the degrees at each endpoints of edges\n",
    "x1 = []\n",
    "y1 = []\n",
    "for e in G0.edges:\n",
    "    x1.append(degrees[e[0]])\n",
    "    y1.append(degrees[e[1]])\n",
    "    x1.append(degrees[e[1]])\n",
    "    y1.append(degrees[e[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "# Edge-centric assortativity is the pearson correlation of such vectors\n",
    "r, p = pearsonr(x1, y1)\n",
    "print(\"Degree assortativity coefficient: %1.4f (p-value < 0.001? %s)\" % (r, p < 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node-centric assortativity is the power-fit of such vectors\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(node_assort[\"k\"]), np.log(node_assort[\"neigh_k\"]))\n",
    "print(\"Degree assortativity coefficient: %1.4f (p-value < 0.001? %s)\" % (slope, p_value < 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-teddy",
   "metadata": {},
   "source": [
    "# Configuration Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare to a null model based on the LCC, unipartite\n",
    "jimmyJo = list(dict(G0.degree).values())\n",
    "CM = nx.configuration_model(jimmyJo)\n",
    "#nx.draw(CM, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bipartite configuration model based on the entire dataset\n",
    "Bi_CM = nx.algorithms.bipartite.generators.configuration_model(e_p, e_c)\n",
    "#nx.draw(Bi_CM, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bipartite that is only the LCC\n",
    "Bi_CM_0 = nx.algorithms.bipartite.generators.configuration_model(e_p1, e_c1)\n",
    "#nx.draw(Bi_CM_0, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration model based on the projection of people\n",
    "P_nodes_projected = list(dict(P.degree).values())\n",
    "P_CM = nx.configuration_model(P_nodes_projected)\n",
    "nx.draw(P_CM, node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-recorder",
   "metadata": {},
   "source": [
    "# Checking for Assortativity (Homophily)\n",
    "\n",
    "### *Assortativity measures the similarity of connections in the graph with respect to the given attribute. Perfect assortativity is 1, while perfect disassortativity is -1. The whole network is quite disassortative.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assortativity coefficient of the Entire Network\n",
    "nx.attribute_assortativity_coefficient(G, \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assortativity coefficient of the LCC\n",
    "nx.attribute_assortativity_coefficient(G0, \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-current",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-gazette",
   "metadata": {},
   "source": [
    "#### More powerlaw stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use the power law (f function) with its logarithm (log_f), to fit it to the log of the CCDF in curve_fit. This\n",
    "# is done because we want to minimize the relative error, not the absolute error (since the tail of the \n",
    "# distribution is very important, but it contributes very little to the absolute error).\n",
    "\n",
    "#popt, pcov = curve_fit(log_f, ccdf_lcc[\"Degree (d)\"], np.log10(ccdf_lcc[\"ccdf: P(X>=d)\"]), p0 = (1, 1))\n",
    "#ccdf_lcc[\"fit\"] = ccdf_lcc.apply(lambda x: f(x[\"Degree (d)\"], popt[0], popt[1]), axis = 1)\n",
    "\n",
    "#ax = plt.gca()\n",
    "#ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"ccdf: P(X>=d)\", color = \"#e41a1c\", loglog = True, ax = ax)\n",
    "#ccdf_lcc.plot(kind = \"line\", x = \"Degree (d)\", y = \"fit\", color = \"#377eb8\", loglog = True, ax = ax)\n",
    "#plt.savefig(\"../Report/ccdf_lcc_fit_2.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-wrist",
   "metadata": {},
   "source": [
    "### Non-square adjacency matrix, and stocastic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-square adjacency matrix\n",
    "adjmat = nx.algorithms.bipartite.matrix.biadjacency_matrix(G, top_nodes)\n",
    "print(adjmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project along smaller axis\n",
    "if adjmat.shape[0] == 551:\n",
    "    adjmat_proj = adjmat.dot(adjmat.T)\n",
    "else:\n",
    "    adjmat_proj = adjmat.T.dot(adjmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make stocastic\n",
    "adjmat_proj_stoc = adjmat_proj / adjmat_proj.sum(axis = 1)\n",
    "print(adjmat_proj_stoc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82a91a22060084f3e8dbe72ba49a002eddd687e7ed0e7d249946fe1b995c1ddc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
